@inproceedings{Kim2025Looking,
    author = {Kim, Ryan and Shinozaki-Conefrey, Kaishuu and Torrens, Paul M.},
    title = {Looking for Answers: Gaze and Brain Activity as Simulation Outputs},
    year = {2025},
    isbn = {9798400715914},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3726301.3731539},
    doi = {10.1145/3726301.3731539},
    abstract = {Behavioral agency relies on our ability to observe and mentally interpret our surroundings. However, interactions between gaze and brain activity often escape data capture and are difficult to model, as their dynamics are sensitive to individual differences and situational context. We examine how immersive virtual reality (VR), brain-computer interfaces (BCIs), and agent-based models (ABMs) can combine to overcome these limitations. We show that electroencephalography (EEG), coupled to VR head-mounted displays (HMDs) and single-board computers (SBCs), can inform simulations of road-crossing with mixtures of real, thinking humans and synthetic agents.},
    booktitle = {Proceedings of the 39th ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
    pages = {186-187},
    numpages = {2},
    location = {Santa Fe, NM, USA},
    series = {SIGSIM-PADS '25}
}