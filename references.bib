
@Article{Torrens2024Using,
    AUTHOR = {Torrens, Paul M. and Kim, Ryan},
    TITLE = {Using Immersive Virtual Reality to Study Road-Crossing Sustainability in Fleeting Moments of Space and Time},
    JOURNAL = {Sustainability},
    VOLUME = {16},
    YEAR = {2024},
    NUMBER = {3},
    ARTICLE-NUMBER = {1327},
    URL = {https://www.mdpi.com/2071-1050/16/3/1327},
    ISSN = {2071-1050},
    ABSTRACT = {Despite a history of year-by-year reduction in road-crossing harm and fatality in the United States, the trend reversed course in 2009 and road-crossing has grown more hazardous since. Within this tendency, there has been a marked uptick in risk to urban crossers who are neither children nor elderly. The age group in between these extremes represents a bulk of urban crossers, for whom theoretical explanations for crossing behavior that are focused on youth and senior crossing factors often do not apply. New insight is likely required to explain why the rate of crossing harm is growing for the 20-44 age group, but declining among the young and elderly. However, it is difficult to experiment with crossing scenarios in a real-world context, where significant dangers are present and for which the uniqueness of crossers and crossing sites is abundant. In this paper, we introduce an end-to-end system for examining crossing behavior using a unique combination of real human crossing behavior, made safe through the combination of agent-based models, motion capture, virtual geographic environments, and immersive technologies from virtual reality. We demonstrate that this combination of methods can be deployed to examine very high resolution and very high specificities of crossing scenarios and behaviors, with reach to individual crossers and their judgment over tiny windows of space and time. We demonstrate that the system can reproduce known effects from the theoretical literature and from existing case studies, while also generating huge swaths of empirical and diagnostically useful data on crossing actions, interactions, and reactions relative to fleeting events and phenomena of urban geography, traffic dynamics, and ambient pedestrian crowds. To prove the concept, we deploy the system to investigate crossing judgment behavior among the 20-44 age group.},
    DOI = {10.3390/su16031327}
}

@Article{Torrens2024Evoking,
    author = {Paul M. Torrens and Ryan Kim},
    title = {Evoking embodiment in immersive geosimulation environments},
    journal = {Annals of GIS},
    volume = {30},
    number = {1},
    pages = {35--66},
    year = {2024},
    publisher = {Taylor \& Francis},
    doi = {10.1080/19475683.2024.2316601},
    URL = {https://doi.org/10.1080/19475683.2024.2316601},
    eprint = {https://doi.org/10.1080/19475683.2024.2316601},
    abstract = { We tackle the issue of how one might close the gap between geographies of people's behavioural experiences and computer models designed to depict those geographies as simulations. We introduce the idea of Immersive Geosimulation Environments (IGEs) as a methodology for coupling spatial behaviour directly to simulation by providing access to (and interaction with) geographic information in ways that elicit user response as fully realized spatial spatial experiences. Importantly, IGEs allow spatial behaviour to be embodied to geosimulation, rather than remaining vicarious to its geography. To examine the utility of IGE methodology, we demonstrate a worked example in the safety science of road-crossing. We present an end-to-end IGE testbed for examining pedestrian - traffic - environment interactions at the roadside. The IGE is designed to achieve congruence between reality and simulation across two related channels. Congruence in fidelity tackles adherence to real-world counterparts, i.e. the condition that IGE elements should function with authenticity to real-world geographies. Congruence in verisimilitude addresses how realistic IGEs seem to the individual user experience, i.e. an IGE's ability to evoke natural spatial behaviour within model scenarios. Our results point to the significance of embodiment in closing the reality gap. We posit that facilitating the formation of action maps, which relate models to users' behaviour, could be key in providing functionally embodied geographic information systems and geosimulation systems. }
}

@inproceedings{Kim2024Building,
    author = {Kim, Ryan and Torrens, Paul M.},
    title = {Building Verisimilitude in VR With High-Fidelity Local Action Models: A Demonstration Supporting Road-Crossing Experiments},
    year = {2024},
    isbn = {9798400703638},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3615979.3656060},
    doi = {10.1145/3615979.3656060},
    abstract = {We examine how issues of investigative and experimental parity between real-world domain science and virtual reality (VR) involving human-environment behavior might be advanced, particularly in the use case of safety science for road-crossing. Our contribution centers on a VR-based traffic flow simulation to recreate, with high fidelity relative to the real world, dynamics of hyper-local interaction between traffic, people, and the roadside environment. An initial demonstration of the system shows that 22 participants responded with high levels of presence, and with high propensity toward natural behavior across road-crossing dimensions. We report these findings even with low-resolution graphic elements. Our results highlight that high levels of user-identified situational verisimilitude (i.e., appearing authentic, particularly to the senses) can be achieved, even with low-resolution graphical depictions. The key, we argue, is the design of appropriate low-level action models to drive user embodiment relative to VR assets. We contend that this finding has wider relevance to consideration of potential channels for VR experience more generally.},
    booktitle = {Proceedings of the 38th ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
    pages = {119-130},
    numpages = {12},
    keywords = {3D interaction, AI, Behavioral tree, Embodiment, Microscopic traffic flow, Pathfinding, Pedestrian, Presence, Realism, Simulation, Task load, Virtual reality},
    location = {Atlanta, GA, USA},
    series = {SIGSIM-PADS '24}
}

@article{Torrens2025Sidewalk,
    title = {Sidewalk2Synth: generating synthetic embodied locomotion from real-world streetscapes},
    volume = {4},
    ISSN = {2731-6963},
    url = {http://dx.doi.org/10.1007/s44212-025-00081-z},
    DOI = {10.1007/s44212-025-00081-z},
    number = {1},
    journal = {Urban Informatics},
    publisher = {Springer Science and Business Media LLC},
    author = {Torrens,  Paul M. and Kim,  Ryan},
    year = {2025},
    month = aug 
}

@inproceedings{Kim2025Looking,
    author = {Kim, Ryan and Shinozaki-Conefrey, Kaishuu and Torrens, Paul M.},
    title = {Looking for Answers: Gaze and Brain Activity as Simulation Outputs},
    year = {2025},
    isbn = {9798400715914},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3726301.3731539},
    doi = {10.1145/3726301.3731539},
    abstract = {Behavioral agency relies on our ability to observe and mentally interpret our surroundings. However, interactions between gaze and brain activity often escape data capture and are difficult to model, as their dynamics are sensitive to individual differences and situational context. We examine how immersive virtual reality (VR), brain-computer interfaces (BCIs), and agent-based models (ABMs) can combine to overcome these limitations. We show that electroencephalography (EEG), coupled to VR head-mounted displays (HMDs) and single-board computers (SBCs), can inform simulations of road-crossing with mixtures of real, thinking humans and synthetic agents.},
    booktitle = {Proceedings of the 39th ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
    pages = {186-187},
    numpages = {2},
    location = {Santa Fe, NM, USA},
    series = {SIGSIM-PADS '25}
}

@Article{Kim2024Boundary,
    AUTHOR = {Kim, Ryan and Torrens, Paul M.},
    TITLE = {Boundary SPH for Robust Particle-Mesh Interaction in Three Dimensions},
    JOURNAL = {Algorithms},
    VOLUME = {17},
    YEAR = {2024},
    NUMBER = {5},
    ARTICLE-NUMBER = {218},
    URL = {https://www.mdpi.com/1999-4893/17/5/218},
    ISSN = {1999-4893},
    ABSTRACT = {This paper introduces an algorithm to tackle the boundary condition (BC) problem, which has long persisted in the numerical and computational treatment of smoothed particle hydrodynamics (SPH). Central to the BC problem is a need for an effective method to reconcile a numerical representation of particles with 2D or 3D geometry. We describe and evaluate an algorithmic solution—boundary SPH (BSPH)—drawn from a novel twist on the mesh-based boundary method, allowing SPH particles to interact (directly and implicitly) with either convex or concave 3D meshes. The method draws inspiration from existing works in graphics, particularly discrete signed distance fields, to determine whether particles are intersecting or submerged with mesh triangles. We evaluate the efficacy of BSPH through application to several simulation environments of varying mesh complexity, showing practical real-time implementation in Unity3D and its high-level shader language (HLSL), which we test in the parallelization of particle operations. To examine robustness, we portray slip and no-slip conditions in simulation, and we separately evaluate convex and concave meshes. To demonstrate empirical utility, we show pressure gradients as measured in simulated still water tank implementations of hydrodynamics. Our results identify that BSPH, despite producing irregular pressure values among particles close to the boundary manifolds of the meshes, successfully prevents particles from intersecting or submerging into the boundary manifold. Average FPS calculations for each simulation scenario show that the mesh boundary method can still be used effectively with simple simulation scenarios. We additionally point the reader to future works that could investigate the effect of simulation parameters and scene complexity on simulation performance, resolve abnormal pressure values along the mesh boundary, and test the method’s robustness on a wider variety of simulation environments.},
    DOI = {10.3390/a17050218}
}

@inproceedings{Torrens2025Experiential,
    author = {Torrens, Paul M and Kim, Ryan and Shinozaki-Conefrey, Kaishuu},
    title = {Experiential geosimulation},
    year = {2025},
    isbn = {9798400721847},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3764921.3770147},
    doi = {10.1145/3764921.3770147},
    abstract = {We introduce experiential geosimulation as a medium for co-exploring embodied behavioral geography, physical locomotion and sensorimotor control, and spatial vision and perception. Methodologically, this convergence is approached through interconnection of high-fidelity geographic automata systems, running in virtual geographic environments within virtual reality head-mounted displays, while spatial telematics and neural activity are collected through eye tracking on a single-board computer and encephalography (EEG) is processed from a scalp-mounted brain-computer interface. Data exchange between these diverse geographic information systems allows for the creation of synthetic simulation scenarios that can evoke realistic locomotion and task behavior from real, physically involved human users. Here, we show that the system also entices people's realistic neural activity, which can provide insight into users' experiences as navigation, agency, spatial vision, landmark salience, non-verbal communications, and cognitive where/what reasoning.},
    booktitle = {Proceedings of the 8th ACM SIGSPATIAL International Workshop on Geospatial Simulation},
    pages = {12-20},
    numpages = {9},
    keywords = {geosimulation, virtual reality, brain-computer interface},
    location = {The Graduate Hotel Minneapolis, Minneapolis, MN, USA},
    series = {GeoSIM '25}
}

@Article{Torrens2025Situationally,
    AUTHOR = {Torrens, Paul M. and Kim, Ryan and Shinozaki-Conefrey, Kaishuu},
    TITLE = {Situationally Sensitive Path Planning},
    JOURNAL = {Algorithms},
    VOLUME = {18},
    YEAR = {2025},
    NUMBER = {7},
    ARTICLE-NUMBER = {388},
    URL = {https://www.mdpi.com/1999-4893/18/7/388},
    ISSN = {1999-4893},
    ABSTRACT = {We examine how site-based path planning algorithms for enclosed spaces can be enhanced with situational detail. Addressing this question has led to value propositions in facility design, where there is often a call to match, map, and merge infrastructure considerations and configurations with potential implications for individual, group, and crowd flow through enclosed spaces. Responding to this question also invokes computational propositions, as facility design software is often computationally conservative with few resources devoted to simulation. We show that situational factors—the peculiarities and momentarily fleeting shifts in an individualized context that embody people in their movement through spaces—can be embedded into traditional, computationally lean path planning heuristics in ways that are actionable in widely used facility design software. We achieve this with algorithmic expansion of well-known planning algorithms using node-based architectures that permit the inclusion detail if, when, and where needed in a hyper-localized situational context that nests within site considerations. We demonstrate a proof of concept for use in the popular Unity 3D modeling platform, showing that situationally sensitive path planning can be achieved during the simulation run time of prototypical design scenarios for enclosed spaces with moving individuals, groups, and crowds.},
    DOI = {10.3390/a18070388}
}